{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366135b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torch, os\n",
    "import os\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f5bda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.1 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from torchvision) (2.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchvision) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchvision) (2023.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from jinja2->torch==2.1.1->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from sympy->torch==2.1.1->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f76faead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathImageFolder(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        original_tuple = super(PathImageFolder, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87da9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    dataTransformer = transforms.Compose([transforms.CenterCrop([256, 256]), transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    transformedData = PathImageFolder(root=data_path, transform=dataTransformer)\n",
    "    dataset = torch.utils.data.DataLoader(transformedData, batch_size=12, shuffle=True,\n",
    "                                                            num_workers=2)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f732e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        \n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "             nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x2 = x\n",
    "        for l in range(len(self.features)):\n",
    "            x2 = self.features[l].forward(x2)\n",
    "            self.features[l].AN = x2\n",
    "        x = self.features(x)\n",
    "        self.oldSize = x.size(0)\n",
    "        x = x.view(x.size(0), 256 * 7 * 7)\n",
    "        x2 = x\n",
    "        for l in range(len(self.classifier)):\n",
    "            x2 = self.classifier[l].forward(x2)\n",
    "            self.classifier[l].AN = x2\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d5972bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, num_classes):\n",
    "    net = AlexNet(num_classes)\n",
    "    device = 'cpu'\n",
    "    weights = torch.load(model_path, map_location=torch.device(device))\n",
    "    net.load_state_dict(weights)\n",
    "    net.to(device)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b6e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, train_data):\n",
    "    correct = 0\n",
    "    for idx, (batch_data, batch_classes, batch_paths) in enumerate(train_data):\n",
    "        if torch.cuda.is_available(): batch_data, batch_classes = batch_data.cuda(), batch_classes.cuda()\n",
    "        batch_data, batch_classes = Variable(batch_data), Variable(batch_classes)\n",
    "        scores = net.forward(batch_data)\n",
    "        pred = scores.data.max(1)[1]\n",
    "        correct += torch.sum(pred == batch_classes.data).float()\n",
    "        print('Accuracy', str(100*(correct.item()/len(list(train_data.dataset)))) + \"%\", 'Processed:', idx+1, end = '\\r')\n",
    "    print('Accuracy', str(100*(correct.item()/len(list(train_data.dataset)))) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce48f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(net, test_data):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    for idx, (batch_data, batch_classes, batch_paths) in enumerate(test_data):\n",
    "        if torch.cuda.is_available(): batch_data, batch_classes = batch_data.cuda(), batch_classes.cuda()\n",
    "        batch_data, batch_classes = Variable(batch_data), Variable(batch_classes)\n",
    "        scores = net.forward(batch_data)\n",
    "        pred = scores.data.max(1)[1]\n",
    "        correct += torch.sum(pred == batch_classes.data).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c514bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "def load_data(data_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  \n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65ac7bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:Closed\n",
      "Class:Closed\n"
     ]
    }
   ],
   "source": [
    "train_data = load_data('Downloads/TrainingSet')\n",
    "\n",
    "print('Class:Closed')\n",
    "\n",
    "test_data = load_data('Downloads/TestSet')\n",
    "\n",
    "\n",
    "print('Class:Closed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f30c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8230d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
